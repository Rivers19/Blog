# 自然语言处理简介



## 基本概念

### 什么是自然语言处理？

自然语言处理（Natural Language Processing，简称NLP）就是用计算机来处理、理解以及运用人类语言(如中文、英文等)，它属于人工智能的一个分支，是计算机科学与语言学的交叉学科，又常被称为计算语言学。由于自然语言是人类区别于其他动物的根本标志。

没有语言，人类的思维也就无从谈起，所以自然语言处理体现了人工智能的最高任务与境界，也就是说，只有当计算机具备了处理自然语言的能力时，机器才算实现了真正的智能。



### 自然语言处理与机器翻译

自然语言处理的兴起与机器翻译这一具体任务有着密切联系。机器翻译指的是利用计算机自动地将一种自然语言翻译为另外一种自然语言。例如自动将英文“I like Beijing Tiananmen Square”翻译为“我爱北京天安门”，或者反过来将“我爱北京天安门”翻译为“I like Beijing Tiananmen Square”。由于人工进行翻译需要训练有素的双语专家，翻译工作非常耗时耗力。更不用说需要翻译一些专业领域文献时，还需要翻译者了解该领域的基本知识。世界上有超过几千种语言，而仅联合国的工作语言就有六种之多。如果能够通过机器翻译准确地进行语言间的翻译，将大大提高人类沟通和了解的效率。

《圣经》里有一个故事说巴比伦人想建造一座塔直通天堂。建塔的人都说着同一种语言，心意相通、齐心协力。上帝看到人类竟然敢做这种事情，就让他们的语言变得不一样。因为人们听不懂对方在讲什么，于是大家整天吵吵闹闹，无法继续建塔。后来人们把这座塔叫作巴别塔，而“巴别”的意思就是“分歧”。虽然巴别塔停建了，但一个梦想却始终萦绕在人们心中：人类什么时候才能拥有相通的语言，重建巴别塔呢？机器翻译被视为“重建巴别塔”的伟大创举。假如能够实现不同语言之间的机器翻译，我们就可以理解世界上任何人说的话，与他们进行交流和沟通，再也不必为相互不能理解而困扰。

事实上，“人工智能”被作为一个研究问题正式提出来的时候，创始人把计算机国际象棋和机器翻译作为两个标志性的任务，认为只要国际象棋系统能够打败人类世界冠军，机器翻译系统达到人类翻译水平，就可以宣告人工智能的胜利。四十年后的1997年，IBM公司的深蓝超级计算机已经能够打败国际象棋世界冠军卡斯帕罗夫。而机器翻译到现在仍无法与人类翻译水平相比，从此可以看出自然语言处理有多么困难！



## 历史发展

### 起步阶段

1954年的[乔治城实验](https://zh.wikipedia.org/w/index.php?title=喬治城實驗&action=edit&redlink=1)涉及全部[自动翻译](https://zh.wikipedia.org/w/index.php?title=自動翻譯&action=edit&redlink=1)超过60句俄文成为英文。研究人员声称三到五年之内即可解决机器翻译的问题。不过实际进展远低于预期，1966年的[ALPAC报告](https://zh.wikipedia.org/w/index.php?title=ALPAC報告&action=edit&redlink=1)发现十年研究未达预期目标，机器翻译的研究经费遭到大幅削减。一直到1980年代末期，[统计机器翻译](https://zh.wikipedia.org/wiki/统计机器翻译)系统发展出来，机器翻译的研究才得以更上一层楼。

1960年代发展特别成功的NLP系统包括[SHRDLU](https://zh.wikipedia.org/w/index.php?title=SHRDLU&action=edit&redlink=1)——一个词汇设限、运作于受限如“[积木世界](https://zh.wikipedia.org/wiki/積木世界)”的一种自然语言系统，以及1964-1966年[约瑟夫·维森鲍姆](https://zh.wikipedia.org/wiki/约瑟夫·维森鲍姆)模拟“[个人中心治疗](https://zh.wikipedia.org/wiki/個人中心治療)”而设计的[ELIZA](https://zh.wikipedia.org/w/index.php?title=ELIZA&action=edit&redlink=1)——几乎未运用人类思想和感情的消息，有时候却能呈现令人讶异地类似人之间的交互。“病人”提出的问题超出ELIZA 极小的知识范围之时，可能会得到空泛的回答。例如问题是“我的头痛”，回答是“为什么说你头痛？”

1970年代，程序员开始设计“概念本体论”（conceptual ontologies）的程序，将现实世界的信息，架构成计算机能够理解的数据。实例有MARGIE、SAM、PAM、TaleSpin、QUALM、Politics以及Plot Unit。许多[聊天机器人](https://zh.wikipedia.org/wiki/聊天機器人)在这一时期写成，包括[PARRY](https://zh.wikipedia.org/w/index.php?title=PARRY&action=edit&redlink=1) 、[Racter](https://zh.wikipedia.org/w/index.php?title=Racter&action=edit&redlink=1) 以及[Jabberwacky](https://zh.wikipedia.org/w/index.php?title=Jabberwacky&action=edit&redlink=1) 。



### 1980s以来发展趋势

二十世纪八十年代以来的趋势就是，基于语言规则的理性主义方法不断受到质疑，大规模语言数据处理成为目前和未来一段时期内自然语言处理的主要研究目标。统计学习方法越来越受到重视，自然语言处理中越来越多地使用机器自动学习的方法来获取语言知识。

#### 21世纪

迈进21世纪，我们已经进入了以互联网为主要标志的海量信息时代，这些海量信息大部分是以自然语言表示的。一方面，海量信息也为计算机学习人类语言提供了更多的“素材”，另一方面，这也为自然语言处理提供了更加宽广的应用舞台。

#### 自然语言处理应用

- 搜索引擎逐渐成为人们获取信息的重要工具，涌现出以百度、谷歌等为代表的搜索引擎巨头；
- 机器翻译也从实验室走入寻常百姓家，谷歌、百度等公司都提供了基于海量网络数据的机器翻译和辅助翻译工具；
- 基于自然语言处理的中文（输入法如搜狗、微软、谷歌等输入法）成为计算机用户的必备工具；
- 带有语音识别的计算机和手机也正大行其道，协助用户更有效地工作学习。

总之，随着互联网的普及和海量信息的涌现，自然语言处理正在人们的日常生活中扮演着越来越重要的作用。然而，面向海量的大规模文本数据，人们面临的一个严峻事实是，如何有效利用海量信息，人们逐渐意识到，单纯依靠统计方法已经无法快速有效地从海量数据中学习语言知识。

#### 深度学习的促进

随着2013年word2vec技术的发表，以神经网络为基础的深度学习技术开始在自然语言处理中广泛使用，深度学习的分布式语义表示和多层网络架构具有强大的拟合和学习能力，显著提升了自然语言处理各种任务的性能，成为现阶段自然语言处理的主要技术方案。

深度学习是纯的数据驱动技术方案，需要从大规模标注数据中学习特定任务相关的复杂模式。一方面，有些学者开始探索面向大规模无标注文本数据的深度学习模型，如ELMo，GPT、BERT等，可以看做从大规模数据中学习知识的极致探索；另一方面，现有深度学习技术尚未考虑人类积累的丰富知识（包括语言知识、世界知识、常识知识、认知知识、行业知识等），如果将深度学习看做经验主义方法，将符号知识看做理性主义方法，那么如何充分发挥基于规则的理性主义方法和基于统计的经验主义方法的优势，两者互相补充，更好、更快地进行自然语言处理，仍然是我们需要探索的重要课题。

自然语言处理作为一个年龄尚不足一个世纪的新兴学科，正在进行着突飞猛进的发展。回顾自然语言处理的发展历程，并不是一帆风顺，有过低谷，也有过高潮。

#### 现在正面临着新的挑战和机遇

例如，目前网络搜索引擎基本上还停留在关键词匹配，缺乏深层次的自然语言处理和理解。语音识别、文字识别、问答系统、机器翻译等目前也只能达到很基本的水平。路漫漫其修远兮，自然语言处理作为一个高度交叉的新兴学科，不论是探究自然本质还是付诸实际应用，在将来必定会有令人期待的惊喜和异常快速的发展。

## 自然语言处理主要范畴

- [文本朗读](https://zh.wikipedia.org/w/index.php?title=文本朗讀&action=edit&redlink=1)（Text to speech）/[语音合成](https://zh.wikipedia.org/wiki/語音合成)（Speech synthesis）
- [语音识别](https://zh.wikipedia.org/wiki/語音識別)（Speech recognition）
- [中文自动分词](https://zh.wikipedia.org/wiki/中文自动分词)（Chinese word segmentation）
- [词性标注](https://zh.wikipedia.org/w/index.php?title=词性标注&action=edit&redlink=1)（Part-of-speech tagging）
- [句法分析](https://zh.wikipedia.org/w/index.php?title=句法分析&action=edit&redlink=1)（Parsing）
- [自然语言生成](https://zh.wikipedia.org/wiki/自然語言生成)（Natural language generation）
- [文本分类](https://zh.wikipedia.org/w/index.php?title=文本分类&action=edit&redlink=1)（Text categorization）
- [信息检索](https://zh.wikipedia.org/wiki/信息检索)（Information retrieval）
- [信息抽取](https://zh.wikipedia.org/wiki/信息抽取)（Information extraction）
- [文字校对](https://zh.wikipedia.org/wiki/校對)（Text-proofing）
- [问答系统](https://zh.wikipedia.org/wiki/問答系統)（Question answering）
    - 给一句人类语言的问句，决定其答案。 典型问题有特定答案 (像是加拿大的首都叫什么?)，但也考虑些开放式问句(像是人生的意义是是什么?)

- [机器翻译](https://zh.wikipedia.org/wiki/機器翻譯)（Machine translation）

- [自动摘要](https://zh.wikipedia.org/w/index.php?title=自動摘要&action=edit&redlink=1)（Automatic summarization）
    - 产生一段文字的大意，通常用于提供已知领域的文章摘要，例如产生报纸上某篇文章之摘要

- [文字蕴涵](https://zh.wikipedia.org/wiki/文字蘊涵)（Textual entailment）
- [命名实体识别](https://zh.wikipedia.org/wiki/命名实体识别)（Named entity recognition）



## 自然语言处理主要难点

### 消歧问题

词法分析、句法分析、语义分析等过程中存在的歧义问题，简称为消歧。而正确的消歧需要大量的知识，包括语言学知识（如词法、句法、语义、上下文等）和世界知识（与语言无关）。这带来自然语言处理的两个主要困难。

#### 语言中充满了大量的歧义

这主要体现在词法、句法及语义三个层次上。歧义的产生是由于自然语言所描述的对象――人类活动非常复杂，而语言的词汇和句法规则又是有限的，这就造成同一种语言形式可能具有多种含义。

例如单词定界问题是属于词法层面的消歧任务。在口语中，词与词之间通常是连贯说出来的。在书面语中，中文等语言也没有词与词之间的边界。由于单词是承载语义的最小单元，要解决自然语言处理，单词的边界界定问题首当其冲。特别是中文文本通常由连续的字序列组成，词与词之间缺少天然的分隔符，因此中文信息处理比英文等西方语言多一步工序，即确定词的边界，我们称为“中文自动分词”任务。通俗的说就是要由计算机在词与词之间自动加上分隔符，从而将中文文本切分为独立的单词。例如一个句子“今天天气晴朗”的带有分隔符的切分文本是“今天|天气|晴朗”。中文自动分词处于中文自然语言处理的底层，是公认的中文信息处理的第一道工序，扮演着重要的角色，主要存在新词发现和歧义切分等问题。我们注意到：正确的单词切分取决于对文本语义的正确理解，而单词切分又是理解语言的最初的一道工序。这样的一个“鸡生蛋、蛋生鸡”的问题自然成了（中文）自然语言处理的第一条拦路虎。

其他级别的语言单位也存在着各种歧义问题。例如在短语级别上，“进口彩电”可以理解为动宾关系（从国外进口了一批彩电），也可以理解为偏正关系（从国外进口的彩电）。又如在句子级别上，“做手术的是她的父亲”可以理解为她父亲生病了需要做手术，也可以理解为她父亲是医生，帮别人做手术。总之，同样一个单词、短语或者句子有多种可能的理解，表示多种可能的语义。如果不能解决好各级语言单位的歧义问题，我们就无法正确理解语言要表达的意思。

#### 消歧的困难

消除歧义所需要的知识在获取、表达以及运用上存在困难。由于语言处理的复杂性，合适的语言处理方法和模型难以设计。

##### 上下文知识的获取

在试图理解一句话的时候，即使不存在歧义问题，我们也往往需要考虑上下文的影响。所谓的“上下文”指的是当前所说这句话所处的语言环境，例如说话人所处的环境，或者是这句话的前几句话或者后几句话，等等。假如当前这句话中存在指代词的时候，我们需要通过这句话前面的句子来推断这个指代词是指的什么。我们以“小明欺负小亮，因此我批评了他”为例。在其中的第二句话中的“他”是指代“小明”还是“小亮”呢？要正确理解这句话，我们就要理解上句话“小明欺负小亮”意味着“小明”做得不对，因此第二句中的“他”应当指代的是“小明”。由于上下文对于当前句子的暗示形式是多种多样的，因此如何考虑上下文影响问题是自然语言处理中的主要困难之一。

##### 背景知识问题

 正确理解人类语言还要有足够的背景知识。举一个简单的例子，在机器翻译研究的初期，人们经常举一个例子来说明机器翻译任务的艰巨性。在英语中“The spirit is willing but the flesh is weak.”，意思是“心有余而力不足”。但是当时的某个机器翻译系统将这句英文翻译到俄语，然后再翻译回英语的时候，却变成了“The Voltka is strong but the meat is rotten.”，意思是“伏特加酒是浓的，但肉却腐烂了”。从字面意义上看，“spirit”（烈性酒）与“Voltka”（伏特加）对译似无问题，而“flesh”和“meat”也都有肉的意思。那么这两句话在意义上为什么会南辕北辙呢？关键的问题就在于在翻译的过程中，机器翻译系统对于英语成语并无了解，仅仅是从字面上进行翻译，结果自然失之毫厘，差之千里。

从上面的两个方面的主要困难，我们看到自然语言处理这个难题的根源就是人类语言的复杂性和语言描述的外部世界的复杂性。人类语言承担着人类表达情感、交流思想、传播知识等重要功能，因此需要具备强大的灵活性和表达能力，而理解语言所需要的知识又是无止境的。那么目前人们是如何尝试进行自然语言处理的呢？



## 自然语言处理的思路

目前人们主要通过两种思路来进行自然语言处理，一种是基于规则的理性主义，另外一种是基于统计的经验主义。

### 基于规则的理性主义

理性主义方法认为，人类语言主要是由语言规则来产生和描述的，因此只要能够用适当的形式将人类语言规则表示出来，就能够理解人类语言，并实现语言之间的翻译等各种自然语言处理任务。

### 基于统计的经验主义

经验主义方法则认为，从语言数据中获取语言统计知识，有效建立语言的统计模型。因此只要能够有足够多的用于统计的语言数据，就能够理解人类语言。

### 问题

当面对现实世界充满模糊与不确定性时，这两种方法都面临着各自无法解决的问题。例如，人类语言虽然有一定的规则，但是在真实使用中往往伴随大量的噪音和不规范性。理性主义方法的一大弱点就是鲁棒性差，只要与规则稍有偏离便无法处理。而对于经验主义方法而言，又不能无限地获取语言数据进行统计学习，因此也不能够完美地理解人类语言。



## 与计算机视觉相比，自然语言有何特点

从图像和语言两种模态来看，对文本处理技术的大规模应用要早于计算机视觉。将图像和语言中的处理对象做一个不太严谨的对应。如下图所示，大体上像素类似于语言中的字母；图像中的对象类似于语言中的单词/概念；图像中对象组成的场景类似于语言中的句子表达的语义；视频则类似于语言中的篇章（文章）。

![image-20191009182010011](https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2019-10-09-102010.png)

在这种类比下看，NLP/IR在单词层面的处理要比CV中的图像识别简单得多，只需要做一下tokenization、lemmatization、stemming等（中文复杂一些需要额外做自动分词），就可以利用关键词匹配完成很多任务，例如信息检索、文本分类、拼写纠错、情感分析、关键词提取等等，实际上已经得到非常广泛的应用，如搜索引擎、拼音输入法、新闻分类、阅读推荐等。

而由于图像中对象的复杂性和多样性，仅在对象识别层面，甚至特定的人脸识别，还有很多技术挑战。只不过是近年来，由于深度学习对非结构数据的强大表示和学习能力，开始让对象识别走向了实用化。

而进入到更高层面，例如面向图像的场景图构建，面向文本的句法语义分析，都需要对复杂语境（上下文）的精准而强大的建模能力。所以我感觉，并非NLP发展缓慢，只是两个领域的发展节奏和阶段不同。进入高层任务后，两个领域都将面临共同的关键挑战，都可以归结为复杂语境下的多对象（图像中是不同对象，文本中是不同概念）的语义组合问题。





## 中文NLP vs 英文NLP在理论、处理上的异同点, 中文 NLP有何独特之处

从实用文本分析技术而言，如果只做主题聚类、文本分类等任务的话，中英文最大差别就在于，中文需要做自动分词，相关工具包已经很多了，包括题主提到的Jieba，还有哈工大的LTP，北理工的ICTCLAS，还有我们组研制的THULAC。当然，在文本分类时，到底是选词还是Ngram作为特征，在SVM+BOW时代曾是个问题。进入到深度学习时代，就直接可以用基于字的神经网络模型了。

从NLP研究角度而言，中英文在词性标注、句法分析等任务上颇有差异。主要体现在英语有明显的屈折变化（单复数、时态等）而汉语缺少这些屈折变化，亦即有学者总结的“汉语重义合，英语重形合”。所以，英语里一个词被标为动词还是名词，没有太多争议；汉语里一个词应该被标为动词还是名词，例如“热爱学习”、“劳动光荣”中的“学习”、“劳动”如果按照英文语法规范应当标注为名词。著名语言学家沈家煊先生就曾提出“汉语动词和名词不分立”的理论。在句法分析层面汉语也有一些自己的特点，具体需要请教专业的语言学家解答了。

中英文相关分析任务的错误率问题。之所以在一些任务上中文分析性能显著低于英文，除了中文缺少屈者变化、有更多自由度从而提升了分析难度的原因外，中文标注资源相对较少、标注质量相对较低也是关键原因之一。语言资源标注既需要语言学家和计算机学者的通力合作，需要花费大量精力和时间，在国内环境下太费力不讨好了，希望未来会有改观。

从更广阔的语言研究角度而言，中英由于各自承载了两种截然不同的人类群体的文化信息，所以在更深层的文化内涵会有更明显的分野，例如两种语言的词汇联想网络、隐喻风格等，可能会有更大的不同。也许在NLP技术日渐成熟之后，我们可以透过语言更加定量地分析两种不同文化的差异。



## 参考资料

本文综合各处资料整理，来源如下：

1. 维基百科.自然语言处理
2. 刘知远.自然语言处理简介.清华大学计算机系
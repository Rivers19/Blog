# 基于特定客服领域对话系统的研究与实现

## 一、研究内容

针对基于特定领域的客服机器人涉及到的单轮问答和多轮对话的不同实现方式，进行详细的阐述。并对涉及到的算法进行设计和实现，主要研究内容有以下几个方面： 

#### 1. 中文文本数据预处理方法的研究。 

根据中文语法和中文文本的特点，本文研究点有：

- 研究中文分词方法效果和性能。
- 研究中文文本在计算机中的表示方法。
- 研究中文文本分类在聊天机器人中的应用。 

#### 2. 单轮对话关键技术的设计和实现。 

根据不同领域的客服机器人的特点，研究特定领域知识库的构建方法，根据单轮对话的特性不断优化知识库和算法的设计。并进行性能测试。 

#### 3. 基于上下文的多轮对话机制的研究 

在提供一问一答能力的基础上，尝试研究带有上下文信息的多轮对话机制的实现方法，主要研究以下几点：

- 针对中文对话中意图识别的研究 
- 中文文本中实体提取的研究。
- 如何将各个算法有机地集成到一起。



## 二、相关技术

### 1. 中文自然语言处理

#### 1.1 中文分词

三大方向：

- **基于词典的分词方法** ，这种方法是一种较为传统的分词方法。将语料中的单词串和人工标记的词典进行一一地比较，如果可以在标记中找到该单词串，则认为可以进行分词，反之不可以进行分词。
    - 优点：这种方法虽然是一种比较机械的方法，但是实现比较简单而且实用性比较强。
    - 缺点：有制约条件，词典的完备性成为这种方法的一个巨大的瓶颈，统计可以得出，一个七万词的词典去切分一万五千词的文章，仍然有三分之一以上的单词不能被切分出来。 
- **基于语法分析的分词方法** ，这种方法的思想就是分词的时候同时进行语法的分析，利用语义规则进行词性标注，从而可以解决分词时出现歧义的问题。
    - 优点：解决分词时的歧义问题
    - 缺点：中国文字博大精深，存在的语法知识，句法知识等十分的庞杂，这种方法还没有达到令人满意的
        效果。 
- **基于统计的分词方法** ，这种方法的原理就是根据某个高频词在文档中出现的次数来认定该单词能否进行分词。
    - 优点：汉字相邻的频率可以很好的反映他们是否可以进行分词。中文单词其实就是汉字的一种组合，相邻字符出现的次数多了以后，就越有可能组成一个单词。

#### 1.2 词向量

- 用数学向量表示单词
- **One-Hot** ：把每个单词都表示成一个多维的向量，这个向量的维度就是词典的大小。该向量绝大多数维度的值都是零，只有其中的一个维度的值为 1，而这个维度就表示为该向量代表的单词。
    - 优点：表达直观
    - 缺点：在处理一些涉及大词典、近义词等应用中无法达到预想效果
        - 维度灾难：词典越大，需要表示的向量也就越多，相应地词向量维度也就越大，维度灾难就随之而来；
        - 基于错误的假设： One-Hot 方式是基于这样一种假设，假设任意两个词之间是没有任何关系的，很显然这个假设是错误的。
- **词向量的分布式表达** ：
    - 优点：克服了Ont-Hot 的两大缺陷。将文本中的每一个词语映射为向量空间一个固定维度的向量，这个向量的维度不会随着词典的增大而增大，而且这个维度可以根据语料规模自定义。这些词向量组成了一个向量空间，每个词向量都可以映射为空间的某一个点，这两点之间的距离，可简单看作两个词的相似度。 

### 2. 深度神经网络

#### 2.1 卷积神经网络CNN

- 与普通神经网络非常相似，由具有可训练的权重和偏移的神经元组成。每个神经元接收一些输入，执行一个卷积，并使用非线性函数激活它。
- 整个网络仍然表现出一个单一的非线性分数函数：从一端的原始数据特征到另一端的类得分。
- 在最后一层（全连接层）上仍然有一个损失函数，规则神经网络开发的所有技巧仍然适用。 
- 简单的卷积神经网络是一系列的层结构，每一层都通过一个可微分函数将一个激活量转换为另一个激活量。
- 一般由三种主要类型的层次结构来构成卷积神经网络：卷积层，池化层和全连接层。

- 卷积层是卷积神经网络的核心组成部分，它进行了大量卷积计算。卷积层的参数由多个可训练的过滤器组成。这个过滤器也叫做卷积核。每个卷积核在维度上（沿纵轴和横轴）都很小，但会延伸到输入的整个深度。

    <img src="https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-12-083453.png" alt="image-20200412163453691" style="zoom:67%;" />

- 池化层也是卷积神经网络中不可缺少的组成部分。在卷积神经网络体系结构中，在卷积层和卷积层间插入池化层是很普遍的。池化层的功能是减小特征的空间大小，以降低模型中计算量和参数量，并且控制过拟合。池化操作在输入的每个特征空间单独运行，并使用最大值池化过程在维度上调整大小。

    ![image-20200412163423318](/Users/rivers/Library/Application Support/typora-user-images/image-20200412163423318.png)

#### 2.2. 循环神经网络RNN

- 和传统神经网络有一些区别：

    - 传统神经网络以及上文提到的卷积神经网络中，网络结构都是分为若干层的，k 层中神经元只接受第 k-1 层神经元发出的激活信号，各神经元之间并没有反馈信息，而且必须接受固定大小的数据，产生固定大小的输出。

        - 传统神经网络优点：在无序定长的问题上是有很大的优势的。使用越多的隐层节点就可以更多的获取输入的信息，就能更好的处理特定的任务。
        - 传统神经网络缺点：传统前馈式神经网络无法针对那种具有一定序列性数据进行有效的学习。

    - RNN 与这种前馈式的神经网络有很大的区别： RNN 只处理单一的输入单元以及上一个时间点的隐层信息。这使得 RNN 可以动态的获取输入信息，而且不受固定长度的制约。 

    - RNN 一个最大的特点：可以记忆之前的学习内容，并利用之前的信息对当前神经元产生影响。

    - 循环神经网络和前馈式神经网络不同的是在网络中增加了一个循环的结构。这样一来隐层单元某时刻的状态不仅和当前输入有关，还可以利用当前时刻之前的输出，这就可以针对呈现序列性的数据进行有效的处理。

    - 文本信息就有着很强的序列性，而实际证明循环神经网络及其变种在 NLP 领域中取得了巨大的成功。 

    - 图 2.3 展示了一个循环神经网络以及其展开的结构图，可以看到每一层的节点都会收到两个输入即前一状态的输出和当前状态的输入，即每一层神经元节点都不仅仅与当前输入状态有关，而且和前面的输入状态有关。这也就是循环神经网络的一个重要的特点。 

        ![image-20200412171759262](https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-12-091759.png)

#### 2.3 RESTful API

- [REST API Tutorial](https://restfulapi.net/)
- [RESTful架构详解](https://www.runoob.com/w3cnote/restful-architecture.html)

## 三. 客服机器人系统设计

### 1. 总体架构设计

#### 1.1 客服机器人软件应用结构图

- 系统软件体系结构：

<img src="https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-12-131209.png" alt="image-20200412211209362 " style="zoom: 40%;" />





- 引擎分层结构：

    <img src="https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-12-131734.png" alt="image-20200412211734289" style="zoom:40%;" />

- 系统架构图

    <img src="https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-12-134354.png" alt="image-20200412214354149" style="zoom:30%;" />

#### 1.2 客服机器人系统拓扑图

<img src="https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-12-142314.png" alt="image-20200412222314082" style="zoom:40%;" />

### 2. 客服机器人系统功能设计

#### 2.1 单轮问答系统设计

- 比如一些常见问题的回答，和重复性很大的问题的回答。单轮问答主要由文本预处理模块和相似度计算模块，在相似度计算模块中需要预先准备词向量词典。这两个模块主要包块分词，词向量转换，相似度计算，阈值比较等核心功能

- 功能模块：

    <img src="https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-12-143509.png" alt="image-20200412223509140" style="zoom:33%;" />

#### 2.2 多轮对话系统设计

- 多轮对话流程：

    ![image-20200413193217379](https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-13-113217.png)

    - 用户要首先针对业务进行配置，其中配置文件可以选择 JSON 格式或者 XML 格式。这里需要说明的是，用户配置完成了以后，在业务不变的情况下，不需要再次配置，因为系统会将用户首次配置的信息以一棵树的形式存储起来。多轮对话配置好后，就可以针对配置的多轮对话进行对话测试。获取用户输入，通过训练好的意图识别和实体识别模型进行相应的意图识别和实体识别，识别完成后接着进行关键词槽的填充，填充完场后就可以根据对话获取的消息进行查库操作或者调用 API 的操作，查库或者调用 API 是最方便和业务有机结合起来的方式。 

    - 多论对话配置信息分为工作域，实体，意图和会话节点信息。其中工作域代表了该多轮对话的配置信息属于哪一个分类，每个租户可能有多个多轮对话，如高校，其中可能有招生方面的多轮对话业务，也可能有财务方面的多轮对话业务。设置工作域首先方便分类，还有就是方便上线和下线某个领域内的多轮对话业务。意图信息存储的就是识别什么样的意图才会命中这个多轮对话，而实体信息则表示需要用户提供哪些实体信息来填充词槽，如查询成绩中的省份就代表了其中的一个插槽。最后，会话节点则是唯一表示了这个多轮对话的配置信息，方便节点的识别和跳转等功能。 意图识别和实体识别是多轮对话模块中的核心算法，通过对用户意图进行分类，命中多轮对话节点，多轮对话节点通过实体识别完成槽位填充。
    - <img src="https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-13-152710.png" alt="image-20200413232710212" style="zoom:40%;" />
        - 当获取到所有需要的信息后，按照预先设定的方法去查询数据库或者调用业务相关的 API 得到最终的答案。这里的 API 可以是网上公开的一些调用接口，比如天气预报的查询等，或者是自己写的业务逻辑封装成 RESTful API，通过多轮对话系统获取 API 所需要的参数，得到相应的回复

### 3. 数据库设计

#### 3.1 单轮问答数据库设计

- faq表：

| 字段     | 类型    | 备注             |
| -------- | ------- | ---------------- |
| id       | int     | 主键、自增、必填 |
| question | varchar | 必填             |
| answer   | varchar | 必填             |
| tenant   | varchar | 必填             |
| high     | varchar | 必填             |
| low      | varchar | 必填             |

#### 3.2 多轮对话数据库设计

- Intent表

| 字段        | 类型    | 备注             |
| ----------- | ------- | ---------------- |
| id          | int     | 主键、自增、必填 |
| name        | varchar | 必填             |
| description | varchar | 缺省：无描述     |

- Intent_example表

| 字段      | 类型    | 备注                 |
| --------- | ------- | -------------------- |
| id        | int     | 主键、自增、必填     |
| example   | varchar | 必填                 |
| entities  | varchar | 必填，存的是意图数组 |
| Intent_id | int     | 必填，外键           |

- entity_example表

| 字段       | 类型    | 备注                 |
| ---------- | ------- | -------------------- |
| example_id | int     | 主键、自增、必填     |
| value      | varchar | 必填                 |
| synonyms   | varchar | 必填，存的是意图数组 |
| entity_id  | int     | 必填，外键           |

## 四、单轮问答系统关键技术设计实现

### 1. 文本预处理

#### 1.1 中文分词介绍

- 中文分词领域尚且存在的问题：
    - 中文消歧
    - 专有名词识别：人名、地名、机构名
    - 新词：城会玩

#### 1.2 中文分词实现

目前常见的开源分词工具主要有 Jieba 分词工具，HanLP 分词工具，THUOCL 分词工具，Pkuseg[20]分词工具以及 FoolNLTK[21]分词工具。

- **Jieba：**
    - Jieba 分词是在 Github 开源的一款分词工具主要用到的算法如下： 
        - 基于词典实现高效的单词构图扫描，生成句子中汉字成词情况所构成的 DAG。 
        - 利用动态规划算法查询到最大概率路径,并寻找出基于频率的最大切分组合。 
        - 对于未出现的单词，采用了基于隐马尔可夫模型，并且使用了 Viterbi  算法。 
    - Jieba 分词号称要做最好的 Python 中文分词组件，现在也支持了很多其他语言。其主要支持三种分词模式，精确模式，全模式和搜索引擎模式。其中适合文本分析的模式就是精确模式。
    - Jieba 分词支持 Python 语言，只需要将源码从 Github 上面下载下来，编译 setup.py 文件即可。使用方法和使用内置包的方法一样简单。引用 Jieba 工具即可。
    - Jieba 分词工具的功能非常丰富，除了分词功能之外还支持用户添加自定义词典这样方便一些专有名词进行分词。还提供关键词提取和词性标注的功能。本文中只需要使用分词的基本功能。 
- **HanLP** ：
    -  是一系列模型和算法组成的 NLP 工具包，其支持中文分词，情感分析，词性标准，命名实体识别，文本摘要以及拼音转换等等功能。其开源的目的是可以让自然语言处理能够在生产环境中得到应用。HanLP 具有功能完善，高效，架构清晰，可自定义的特点。 
    - 本文主要应用的是HanLP的分词功能，其分词功能又可以分为三个不同的模式，分别是 HMM-Bigram，由字构词以及词典分词。
    -  HMM-Bigram 模式是速度和精度最佳平衡的模式，词典分词模式则侧重于速度，针对那些需要高效完成的任务可以使用这种模式，由字构词这种模式，凭借着巨大的语料库可以做到极致的精度，并且可以识别新词适合大量 NLP 任务。 

### 2. 词向量转换

#### 2.1 语料获取

- 爬虫工具：常见的开源爬虫工具也有很多，如基于 Java 语言的 Nutch，基于 Python 的 Pyspider 和 Scrapy框架。 

    <img src="https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-13-155841.png" alt="image-20200413235840459" style="zoom:40%;" />

    

- 爬虫策略：根据网页布局确定爬取内容有哪些 HTML 控件组成。根据 HTML 源代码分析该网页又连接到哪些 URL，根据预先设定的 URL 规则将其添加到待抓取 URL 队列中，等待进行抓取。

#### 2.2 词向量词典

为了提高词向量转换的效率，本文预先训练一个完备的词典。这样一来，首先避免了扩充知识库时再次训练词向量的时间消耗，而且使用词向量词典，使得相似度计算时精度更高

- **Word2vec** :

    - 它的特点就是将单词转换为向量的模式，使得单词和单词之间可以定量的去度量它们之间的关系，挖掘深层次的联系。Word2vec 利用了深度学习思想，将文本数据处理成 N 维向量空间的向量。
    - Word2vec 包括了两种训练词向量的模型CBOW 模型和 Skip-gram 模型。

    <img src="https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-13-160310.png" alt="image-20200414000310174" style="zoom:40%;" />

    - CBOW和Skip-gram异同点：
        - 相同：
            - 两者都是利用了神经网络作为分类算法，最开始每个单词都对应一个 N维向量，经过神经网络的训练后，通过 CBOW 算法或者通过 Skip-gram 算法求得每个向量的最优值。
            - 两种模型的计算都是基于霍夫曼树，其中霍夫曼树的叶子节点的作用是可以作为是神经网络的输出层神经元。其叶子的个数就代表了词汇表的大小。（*霍夫曼树的特点就是权重越高的节点会越靠近根节点，这样一来其编码值也短。这样也符合一般设定，出现频率高的单词编码较短。*）
        - 不同：两种模型在架构设计和模型训练方面都不尽相同。其中，CBOW 的目标是通过上下文来预测当前词语的概率，而 Skip-gram 正好相反，它是根据当前单词来预测上下文的概率。

- **FastText** ：

    - 与Wordv2ec异同：
        - 相同：
            - 从 Word2vec 的 CBOW 模型演变而来，两者网络结构相似，都包含了三层结构，输入层，隐层和输出层。输入都是多个单词的词向量，隐层也都是多个词向量叠加后的平均值。从网络结构看，两者基本上是一致的。
            - 公式推导和分层 Softmax思想和 CBOW 也都一致。
        - 不同：CBOW 输入层只有中心词在特征窗口中的上下文单词，而 FastText 除了这些单词之外，还包含了这些单词 N-gram 字符级别的特征；另外一个不同点是 CBOW 的输出是当前中心词，FastText 的输出是文本对应的类别。

- **词向量训练流程：**

    <img src="https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-13-161601.png" alt="image-20200414001601088" style="zoom:40%;" />

### 3. 相似度计算和阈值比较

#### 3.1 相似度计算

- 语句相似度：指的是在中文语料中，两句话在语义上的相似程度。相似的大小是在[0,1]之间的数值。相似度越接近 1 就表示两句话的在语义上的相似度越大，相反地，相似度越接近 0 则表示了两句话在语义上的相似度越小

- 词向量相似度计算方法：有编辑距离相似度计算，Jaccard 系数相似度计算，TFIDF[25]相似度计算，BM25相似度计算以及 Cosine（余弦）相似度计算等。

- 语句向量计算方法：本文采用直接将组成该句子的所有有效单词的词向量直接相加获取对应的句向量。

    <img src="https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-13-162322.png" alt="image-20200414002322059" style="zoom:33%;" />

- 语句相似度计算方法：余弦相似度

#### 3.2 阈值比较

获取到知识库中每个问题和用户输入问题的相似度以后，究竟哪个问题的答案可以作为机器人最终的回答返回，这里就需要阈值比较来决定。

- 阈值获取：为了获取阈值，预先加载知识库，并从知识库中挑选 100 个问题，并列出其相似问法，作为正例。另外准备 100 个不存在知识库中的问题，作为反例。准备好问题后将问题顺序放入到系统中，并依次获取规律就可以获取阈值。

<img src="https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-13-162656.png" alt="image-20200414002655952" style="zoom:33%;" />

- 可以看到正确命中知识库问题的相似度和错误命中的分界线大致为 0.977，所以就将数值 0.977 作为系统相似度阈值。因为知识库虽然不同，但是向量空间中余弦相似度计算呈现一定的规律，所以可以将 0.977 作为不同知识库的阈值，经试验可知该数值可行。同时系统阈值也支持用户自定义，这里只提供一个经过试验产生的默认值。

### 4. 负载均衡

为了有效的提供稳定的服务，可以在不同的服务器上进行部署。通过多个服务器节点提供服务。这样就需要通过负载均衡的服务器进行分分流，

#### 4.1 负载均衡介绍

- 最早的时候，是利用 DNS 做负载，通过给客户端解析不同的 IP 地址，使得客户端流量可以直连服务器，但是 DNS 的负载策略比较简单无法满足业务需求，负载均衡应运而生。客户端发出的请求会首先到达负载均衡服务器，由它通过一定的负载均衡调度算法将流量合理的分配到不同的服务器节点上面。 
- 负载均衡的算法在一定程度上决定了负载均衡服务器的性能，常见的负载均衡算法有以下几种： 
    - **随机算法** :随机算法，其实是一种按照权重设置随机的策略，这种算法在调用量越大的时候其分布就越均匀。这种方法实现较为简单有效，并且可以根据需要动态的调整权重。 
    - **轮询算法**  :常用轮询算法主要普通轮询算法和加权轮询算法。在各个服务器的计算能力差异不大的时候，就很适合普通的轮询算法。普通轮询算法容易出现较慢的机器累计请求的情况。这就有了加权轮询算法，给提供服务的每个服务器节点附一个权重，计算能力强的服务器就可以加大权重，能力弱的服务器减小权重。 
    - **IP 地址哈希** : 通过用户请求 IP 地址和目的 IP 地址进行哈希值计算，这种算法可以解决动态页面共享 Session 的问题，特定 IP 可以固定的访问同一个后端服务器。 负载均衡的实现也有很多，常见的有 DNS 解析负载均衡，LVS 负载均衡，IP 负
        载均衡，HTTP 重定向负载均衡以及反向代理负载均衡。本文使用的是反向代理负载均衡。 

#### 4.2 负载均衡实现

<img src="https://rivers19-1300325434.cos.ap-beijing.myqcloud.com/2020-04-13-164122.png" alt="image-20200414004121831" style="zoom: 40%;" />

- 本文使用反向代理负载均衡，对用户流量进行合理的分流。通常的代理服务器用 于代理内网对因特网的连接请求。而 **反向代理** 指的是用代理服务器来接受来自因特尔上的请求，然后将来自互联网的请求转发到内部网络的服务器节点上，并将结果返回给发出请求的客户端。本文所用到的反向代理工具是 Nginx。 

- Gunicorn是一款轻量级，高性能的 HTTP 服务器，使用简单，无需配置，只需要简单的指令即可，指令示例如“gunicorn -w 4 -b 127.0.0.1:8080 filepath:app”。其中参数 w 表示了服务器启动的进程数量，参数 b 则表示了 Flask 应用映射的 IP 地址和端口，filepath 则表示了 Flask 文件的路径，app 表示 Flask 实例化对象。 启动服务后，服务器就会自动监听 5000 端口，并开放 5000 端口作为 Nginx 连接。Nginx 服务器需要进行安装和配置，配置文件如下所示：

- ```nginx
    upstream flask { 
             server 38.265.23.111:5000; 
             server 38.265.23.112:5000; } 
    server { 
             listen   80 default_server; 
             location / { 
                     proxy_pass http://127.0.0.1:5000;  
                     proxy_set_header Host $host; 
                     proxy_set_header X-Real-IP $remote_addr;}} 
    
    ```

## 五、多轮对话系统关键技术设计实现

### 1. 多轮对话配置

### 2. 意图识别

### 3.实体识别

### 4.对话策略

## 六、测试与结果分析

### 1. 系统环境

### 2. 算法模型性能测试

### 3. 接口测试

